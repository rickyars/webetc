<!DOCTYPE html>
<html>
<head>
  <title>Simple GPU Compute Test</title>
</head>
<body>
  <h1>Simple GPU Compute Benchmark</h1>
  <pre id="log"></pre>
  <script type="module">
    const log = (msg) => {
      document.getElementById('log').textContent += msg + '\n';
      console.log(msg);
    };

    async function runTest() {
      const adapter = await navigator.gpu.requestAdapter();
      const device = await adapter.requestDevice();

      log('GPU: ' + adapter.name);
      log('Max compute workgroup size: ' + device.limits.maxComputeWorkgroupSizeX);
      log('Max compute invocations per workgroup: ' + device.limits.maxComputeInvocationsPerWorkgroup);
      log('');

      // Simple shader that just does FNV hash (no memory access)
      const shader = `
        @group(0) @binding(0) var<storage, read_write> output: array<u32>;

        fn fnv(x: u32, y: u32) -> u32 {
          return (x * 16777619u) ^ y;
        }

        @compute @workgroup_size(256)
        fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {
          let idx = global_id.x;
          var result = idx;

          // Do 1000 FNV operations
          for (var i = 0u; i < 1000u; i++) {
            result = fnv(result, i);
          }

          output[idx] = result;
        }
      `;

      const shaderModule = device.createShaderModule({ code: shader });
      const pipeline = device.createComputePipeline({
        layout: 'auto',
        compute: { module: shaderModule, entryPoint: 'main' }
      });

      const sizes = [10000, 100000, 1000000];

      for (const size of sizes) {
        const buffer = device.createBuffer({
          size: size * 4,
          usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC
        });

        const bindGroup = device.createBindGroup({
          layout: pipeline.getBindGroupLayout(0),
          entries: [{ binding: 0, resource: { buffer } }]
        });

        // Warm up
        for (let i = 0; i < 3; i++) {
          const encoder = device.createCommandEncoder();
          const pass = encoder.beginComputePass();
          pass.setPipeline(pipeline);
          pass.setBindGroup(0, bindGroup);
          pass.dispatchWorkgroups(Math.ceil(size / 256));
          pass.end();
          device.queue.submit([encoder.finish()]);
          await device.queue.onSubmittedWorkDone();
        }

        // Benchmark
        const iterations = 10;
        const timings = [];

        for (let i = 0; i < iterations; i++) {
          const start = performance.now();

          const encoder = device.createCommandEncoder();
          const pass = encoder.beginComputePass();
          pass.setPipeline(pipeline);
          pass.setBindGroup(0, bindGroup);
          pass.dispatchWorkgroups(Math.ceil(size / 256));
          pass.end();
          device.queue.submit([encoder.finish()]);
          await device.queue.onSubmittedWorkDone();

          timings.push(performance.now() - start);
        }

        const avgTime = timings.reduce((a,b) => a+b) / timings.length;
        const opsPerThread = 1000;
        const totalOps = size * opsPerThread;
        const opsPerSec = totalOps / (avgTime / 1000);

        log(`Size: ${size.toLocaleString()} threads`);
        log(`  Avg time: ${avgTime.toFixed(3)}ms`);
        log(`  Throughput: ${(opsPerSec / 1e9).toFixed(2)} billion ops/sec`);
        log(`  Per-thread time: ${(avgTime / size * 1000).toFixed(3)}Âµs`);
        log('');

        buffer.destroy();
      }
    }

    runTest().catch(e => log('Error: ' + e));
  </script>
</body>
</html>
